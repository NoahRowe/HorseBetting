{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/03/complete-guide-parameter-tuning-xgboost-with-codes-python/\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from helper import *\n",
    "\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold, GridSearchCV, train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "runs = pd.read_pickle(\"../Data/main_1.df\")\n",
    "\n",
    "#FEATURES = ['win_odds', 'horse_race_count', 'place_odds', 'best_odds', 'best_going_record', 'best_horse_record']\n",
    "FEATURES = ['horse_no', 'horse_rating', 'declared_weight', 'actual_weight', 'win_odds', 'draw', 'race_size', \n",
    "            'last_race_result', 'win_percent', 'avg_distance_time', 'going_type_record', 'horse_race_count', \n",
    "            'horse_record', 'surface_record', 'place_odds', 'weight_change_from_average', 'venue_change', \n",
    "            'venue_record', 'days_since_last_race', 'new_horse', 'best_odds', 'best_win_percent', \n",
    "            'best_going_record', 'best_horse_record', 'best_jockey_record', 'best_trainer_record', \n",
    "            'highest_actual_weight', 'lowest_actual_weight', 'start_speed', 'rode_before']\n",
    "\n",
    "TARGET = \"won\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PARAM TUNING STEPS:\n",
    "# find best booster type\n",
    "\n",
    "# set learning rate and find optimal n_estimators\n",
    "\n",
    "# Tune max_depth and min_child_weight\n",
    "\n",
    "# Tune gamma\n",
    "\n",
    "# Tune subsample and colsample_bytree\n",
    "\n",
    "# Regularization params\n",
    "\n",
    "# Lower learning rate and add more trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model, grid, x, y, n_splits=4, n_jobs=4, verbose=2):\n",
    "    \n",
    "    cv = KFold(n_splits=n_splits, shuffle=True)\n",
    "    \n",
    "    gSearch = GridSearchCV(estimator=model, param_grid=grid, n_jobs=n_jobs, cv=cv, scoring=\"accuracy\", verbose=verbose)\n",
    "    \n",
    "    gSearch.fit(x, y)\n",
    "    \n",
    "    print(\"Best Params: \", gSearch.best_params_)\n",
    "    print(\"Score: {}\".format(gSearch.best_score_))\n",
    "    \n",
    "    return gSearch\n",
    "\n",
    "def testModel(search, x, y):\n",
    "    print(\"Determining Test Accuracy...\")\n",
    "    preds = search.predict(x)\n",
    "    score = accuracy_score(y, preds)\n",
    "    print(\"{:.2f}% accuracy\".format(score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   4 out of   4 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'silent': 1}\n",
      "Score: 0.9183606753676548\n"
     ]
    }
   ],
   "source": [
    "# Baseline accuracy - 0.9183606753676548\n",
    "xgb_bl = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=500\n",
    ")\n",
    "grid_bl = {\n",
    "    \"silent\":[1]\n",
    "}\n",
    "#search_bl = trainModel(xgb_bl, grid_bl, runs[FEATURES], runs[TARGET])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 2 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   6 out of   8 | elapsed:  3.2min remaining:  1.1min\n",
      "[Parallel(n_jobs=4)]: Done   8 out of   8 | elapsed:  3.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'booster': 'gblinear'}\n",
      "Score: 0.9199718155215603\n"
     ]
    }
   ],
   "source": [
    "# BOOSTER TYPE\n",
    "xgb_1 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=500\n",
    ")\n",
    "\n",
    "grid_1 = {\n",
    "    'booster':[\"gbtree\", \"gblinear\"]\n",
    "}\n",
    "#search_1 = trainModel(xgb_1, grid_1, runs[FEATURES], runs[TARGET])\n",
    "#best_booster=search_1.best_params_[\"booster\"]\n",
    "best_booster = 'gblinear'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 16 candidates, totalling 64 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:  2.5min\n",
      "[Parallel(n_jobs=4)]: Done  64 out of  64 | elapsed: 14.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'max_depth': 1, 'min_child_weight': 1}\n",
      "Score: 0.9199718009453792\n"
     ]
    }
   ],
   "source": [
    "# max_depth and min_child_weight\n",
    "xgb_2_a = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=500,\n",
    "    booster=best_booster\n",
    ")\n",
    "\n",
    "grid_2_a = {\n",
    "    'max_depth':range(1,11)\n",
    "}\n",
    "search_2_a = trainModel(xgb_2_a, grid_2_a, runs[FEATURES], runs[TARGET], verbose=5)\n",
    "best_max_depth = search_2_a.best_params_[\"max_depth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth and min_child_weight\n",
    "xgb_2_b = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=500,\n",
    "    booster=best_booster\n",
    "    max_depth = \n",
    ")\n",
    "\n",
    "grid_2_b = {\n",
    "    'min_child_weight':range(1,11)\n",
    "}\n",
    "search_2_b = trainModel(xgb_2_b, grid_2_b, runs[FEATURES], runs[TARGET], verbose=5)\n",
    "best_min_child_weight = search_2_b.best_params_[\"min_child_weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma\n",
    "xgb_3 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=500,\n",
    "    booster=best_booster,\n",
    "    max_depth=best_max_depth,\n",
    "    min_child_weight=best_min_child_weight,\n",
    ")\n",
    "\n",
    "grid_3 = {\n",
    "    'gamma':[i/100. for i in range(0,10)]\n",
    "}\n",
    "search_3 = trainModel(xgb_3, grid_3, runs[FEATURES], runs[TARGET])\n",
    "best_gamma = search_3.best_params_[\"gamma\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subsample and colsample_bytree\n",
    "xgb_4 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=500,\n",
    "    booster=best_booster,\n",
    "    max_depth=best_max_depth,\n",
    "    min_child_weight=best_min_child_weight,\n",
    "    gamma=best_gamma,\n",
    ")\n",
    "\n",
    "grid_4 = {\n",
    "    'subsample':[i/10.0 for i in range(2,8)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(2,8)],\n",
    "}\n",
    "#search_4 = trainModel(xgb_4, grid_4, runs[FEATURES], runs[TARGET])\n",
    "best_subsample = search_4.best_params_[\"subsample\"]\n",
    "best_colsample_bytree = search_4.best_params_[\"colsample_bytree\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 5 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Params:  {'reg_alpha': 1e-05}\n",
      "Score: 0.9199718079165962\n"
     ]
    }
   ],
   "source": [
    "# Regularization params\n",
    "xgb_5 = XGBClassifier(\n",
    "    learning_rate =0.1,\n",
    "    n_estimators=500,\n",
    "    booster=best_booster,\n",
    "    max_depth=best_max_depth,\n",
    "    min_child_weight=best_min_child_weight,\n",
    "    gamma=best_gamma,\n",
    "    subsample=best_subsample,\n",
    "    colsample_bytree=best_colsample_bytree,\n",
    ")\n",
    "\n",
    "grid_5 = {\n",
    "    'reg_alpha':[1e-10,1e-9,1e-8,1e-7,1e-6,1e-5,1e-4]\n",
    "}\n",
    "search_5 = trainModel(xgb_5, grid_5, runs[FEATURES], runs[TARGET])\n",
    "best_reg_alpha = search_5.best_params_[\"reg_alpha\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gblinear 1 1 0.0 0.6 0.6 1e-05\n"
     ]
    }
   ],
   "source": [
    "# AFTER THESE ARE FIGURED OUT DECREASE LEARNING RATE AND INCREASE n_est\n",
    "\n",
    "print(best_booster, best_max_depth, best_min_child_weight, best_gamma, best_subsample, best_colsample_bytree, \n",
    "      best_reg_alpha)     \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, chi2\n",
    "\n",
    "runs = pd.read_pickle(\"Data/main_1.df\")\n",
    "runs = runs.iloc[int(len(runs)*.1):,:]\n",
    "num_races = len(np.unique(runs[\"race_id\"]))\n",
    "FEATURES = [\"horse_no\", \"horse_age\", \"horse_rating\", \"declared_weight\", \"actual_weight\", \n",
    "            \"win_odds\", \"draw\", #\"race_size\", \"distance\", \"race_class\", \n",
    "            'last_race_result','win_percent', \n",
    "            'avg_distance_time', 'normal_avg_distance_time',\n",
    "            'going_type_record', 'actual_weight_scaled',\n",
    "            'declared_weight_scaled', 'horse_race_count', \"jockey_record\",\n",
    "            'trainer_record', 'horse_record', 'surface_record', 'place_odds',\n",
    "            'weight_change', 'weight_change_over_time','weight_change_from_average', 'weight_change_increase',\n",
    "            'venue_change','venue_record', 'days_since_last_race', 'new_horse',\n",
    "            'best_odds', 'best_win_percent', 'best_distance_time', 'best_going_record', \n",
    "            'best_horse_record', 'best_jockey_record','best_trainer_record', 'highest_actual_weight', \n",
    "            'lowest_actual_weight', 'start_speed', 'rode_before']\n",
    "\n",
    "\n",
    "#TARGET = 'won'\n",
    "TARGET = 'placed'\n",
    "\n",
    "X = runs[FEATURES]\n",
    "y = runs[TARGET]\n",
    "\n",
    "testPct = 0.2\n",
    "trainIndex = int(num_races * (1-testPct))\n",
    "max_race_id = np.unique(runs[\"race_id\"])[trainIndex]\n",
    "X_train = X.loc[runs[\"race_id\"]<=max_race_id]\n",
    "y_train = y.loc[runs[\"race_id\"]<=max_race_id]\n",
    "X_test = X.loc[runs[\"race_id\"]>max_race_id]\n",
    "y_test = y.loc[runs[\"race_id\"]>max_race_id]\n",
    "race_sizes_for_eval = [len(runs.loc[runs[\"race_id\"]==race_id][\"race_id\"]) for race_id in np.unique(runs.loc[runs[\"race_id\"]>max_race_id][\"race_id\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 17\n",
    "rf_pipe = Pipeline([('skb', SelectKBest(chi2, k = k)),\n",
    "                    ('model', RandomForestClassifier())])\n",
    "lr_pipe = Pipeline([('skb', SelectKBest(chi2, k = k)),\n",
    "                    ('model', LogisticRegression(max_iter=10000))])\n",
    "xgb_pipe = Pipeline([('skb', SelectKBest(chi2, k = k)),\n",
    "                    ('model', XGBClassifier())])\n",
    "gb_pipe = Pipeline([('skb', SelectKBest(chi2, k = k)),\n",
    "                    ('model', GradientBoostingClassifier())])\n",
    "\n",
    "estimators = estimators = [('rf', rf_pipe),\n",
    "                           ('lr', lr_pipe),\n",
    "                           ('xgb', xgb_pipe),\n",
    "                           ('gb', gb_pipe)]\n",
    "lr_stack = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())\n",
    "rf_stack = StackingClassifier(estimators=estimators, final_estimator=RandomForestClassifier())\n",
    "gb_stack = StackingClassifier(estimators=estimators, final_estimator=GradientBoostingClassifier())\n",
    "xgb_stack = StackingClassifier(estimators=estimators, final_estimator=XGBClassifier())\n",
    "\n",
    "soft_voter = VotingClassifier(estimators=estimators, voting='soft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RF ... \n",
      "Training LR ... \n",
      "Training XGB ... \n",
      "Training GB ... \n",
      "Training lr_stack ... \n",
      "Training rf_stack ... \n",
      "Training gb_stack ... \n",
      "Training xgb_stack ... \n",
      "Training soft voter ... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              Pipeline(memory=None,\n",
       "                                       steps=[('skb',\n",
       "                                               SelectKBest(k=17,\n",
       "                                                           score_func=<function chi2 at 0x11a0a66a8>)),\n",
       "                                              ('model',\n",
       "                                               RandomForestClassifier(bootstrap=True,\n",
       "                                                                      ccp_alpha=0.0,\n",
       "                                                                      class_weight=None,\n",
       "                                                                      criterion='gini',\n",
       "                                                                      max_depth=None,\n",
       "                                                                      max_features='auto',\n",
       "                                                                      max_leaf_nodes=None,\n",
       "                                                                      max_samples=None,\n",
       "                                                                      min_impurity_decrease=0.0,\n",
       "                                                                      min_impurity_split=None,\n",
       "                                                                      min_...\n",
       "                                                                          min_impurity_decrease=0.0,\n",
       "                                                                          min_impurity_split=None,\n",
       "                                                                          min_samples_leaf=1,\n",
       "                                                                          min_samples_split=2,\n",
       "                                                                          min_weight_fraction_leaf=0.0,\n",
       "                                                                          n_estimators=100,\n",
       "                                                                          n_iter_no_change=None,\n",
       "                                                                          presort='deprecated',\n",
       "                                                                          random_state=None,\n",
       "                                                                          subsample=1.0,\n",
       "                                                                          tol=0.0001,\n",
       "                                                                          validation_fraction=0.1,\n",
       "                                                                          verbose=0,\n",
       "                                                                          warm_start=False))],\n",
       "                                       verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the models\n",
    "print(\"Training RF ... \")\n",
    "rf_pipe.fit(X_train, y_train)\n",
    "print(\"Training LR ... \")\n",
    "lr_pipe.fit(X_train, y_train)\n",
    "print(\"Training XGB ... \")\n",
    "xgb_pipe.fit(X_train, y_train)\n",
    "print(\"Training GB ... \")\n",
    "gb_pipe.fit(X_train, y_train)\n",
    "print(\"Training lr_stack ... \")\n",
    "lr_stack.fit(X_train, y_train)\n",
    "print(\"Training rf_stack ... \")\n",
    "rf_stack.fit(X_train, y_train)\n",
    "print(\"Training gb_stack ... \")\n",
    "gb_stack.fit(X_train, y_train)\n",
    "print(\"Training xgb_stack ... \")\n",
    "xgb_stack.fit(X_train, y_train)\n",
    "print(\"Training soft voter ... \")\n",
    "soft_voter.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest accuracy: 0.491\n",
      "Logistic Regression accuracy: 0.490\n",
      "Gradient Boosting accuracy: 0.500\n",
      "XGBoost accuracy: 0.488\n",
      "LR Stacking accuracy: 0.502\n",
      "RFStacking accuracy: 0.462\n",
      "GB Stacking accuracy: 0.496\n",
      "XGB Stacking accuracy: 0.488\n",
      "Soft voter accuracy: 0.499\n",
      "Random guessing accuracy: 0.070\n",
      "Betting best odds accuracy: 0.495\n"
     ]
    }
   ],
   "source": [
    "# Create our evaluate function\n",
    "def winnerEval(model, x_test, y_test, race_sizes):\n",
    "    # convert preds into an actual win choice\n",
    "    winPreds = model.predict_proba(x_test)[:, 1]\n",
    "    winCount = 0\n",
    "    temp = 0 \n",
    "    for i, s in enumerate(race_sizes):\n",
    "        low_index = temp\n",
    "        high_index = temp + s\n",
    "        \n",
    "        racePreds = winPreds[low_index:high_index]\n",
    "        raceVals = y_test[low_index:high_index]\n",
    "        \n",
    "        if TARGET=='won':\n",
    "            predWinner = np.argmax(racePreds, axis=0)\n",
    "            actWinner = np.argmax(raceVals, axis=0)\n",
    "        \n",
    "            if predWinner == actWinner:\n",
    "                winCount += 1\n",
    "                \n",
    "        elif TARGET=='placed':\n",
    "            predPlacers = racePreds.argsort()[-3:]\n",
    "            actPlacers = raceVals.argsort()[-3:]\n",
    "            \n",
    "            for val in actPlacers:\n",
    "                if val in predPlacers:\n",
    "                    winCount+=1\n",
    "            \n",
    "        temp += s\n",
    "        \n",
    "\n",
    "    if TARGET=='won':\n",
    "        return winCount/float(len(race_sizes))\n",
    "    else:\n",
    "        return winCount / float(len(race_sizes)*3)\n",
    "\n",
    "# DO ANOTHER FUNCTION THAT IS JUST FINDING THE BEST ODDS HORSE\n",
    "def bestOddsEval(x_test, y_test, race_sizes):\n",
    "    winCount = 0\n",
    "    temp = 0 \n",
    "    for i, s in enumerate(race_sizes):\n",
    "        low_index = temp\n",
    "        high_index = temp + s\n",
    "        \n",
    "        oddsPreds = x_test[low_index:high_index]\n",
    "        raceVals = y_test[low_index:high_index]\n",
    "        \n",
    "        if TARGET=='won':\n",
    "            predWinner = np.argmin(oddsPreds[\"win_odds\"], axis=0)\n",
    "            actWinner = np.argmax(raceVals, axis=0)\n",
    "\n",
    "            if predWinner == actWinner:\n",
    "                winCount += 1\n",
    "            \n",
    "        elif TARGET=='placed':\n",
    "            predPlacers = oddsPreds[\"place_odds\"].argsort()[:3].to_list()\n",
    "            actPlacers = raceVals.argsort()[-3:].to_list()\n",
    "            \n",
    "            for val in actPlacers:\n",
    "                if val in predPlacers:\n",
    "                    winCount+=1\n",
    "                    \n",
    "        temp += s\n",
    "        \n",
    "    if TARGET=='won':\n",
    "        return winCount/float(len(race_sizes))\n",
    "    else:\n",
    "        return winCount / float(len(race_sizes)*3)\n",
    "\n",
    "def randEval(race_sizes):\n",
    "    randCount = 0 \n",
    "    for s in race_sizes:\n",
    "        rand_a = np.random.randint(s)\n",
    "        rand_b = np.random.randint(s)\n",
    "        if rand_a==rand_b:\n",
    "            randCount+=1\n",
    "    return randCount/float(len(race_sizes))\n",
    "\n",
    "randAcc = randEval(race_sizes_for_eval)\n",
    "oddsAcc = bestOddsEval(X_test, y_test, race_sizes_for_eval)\n",
    "        \n",
    "print(\"Random Forest accuracy: {:.3f}\".format(winnerEval(rf_pipe, X_test, y_test, race_sizes_for_eval)))\n",
    "print(\"Logistic Regression accuracy: {:.3f}\".format(winnerEval(lr_pipe, X_test, y_test, race_sizes_for_eval)))\n",
    "print(\"Gradient Boosting accuracy: {:.3f}\".format(winnerEval(gb_pipe, X_test, y_test, race_sizes_for_eval)))\n",
    "print(\"XGBoost accuracy: {:.3f}\".format(winnerEval(xgb_pipe, X_test, y_test, race_sizes_for_eval)))\n",
    "\n",
    "print(\"LR Stacking accuracy: {:.3f}\".format(winnerEval(lr_stack, X_test, y_test, race_sizes_for_eval)))\n",
    "print(\"RFStacking accuracy: {:.3f}\".format(winnerEval(rf_stack, X_test, y_test, race_sizes_for_eval)))\n",
    "print(\"GB Stacking accuracy: {:.3f}\".format(winnerEval(gb_stack, X_test, y_test, race_sizes_for_eval)))\n",
    "print(\"XGB Stacking accuracy: {:.3f}\".format(winnerEval(xgb_stack, X_test, y_test, race_sizes_for_eval)))\n",
    "\n",
    "print(\"Soft voter accuracy: {:.3f}\".format(winnerEval(soft_voter, X_test, y_test, race_sizes_for_eval)))\n",
    "\n",
    "print(\"Random guessing accuracy: {:.3f}\".format(randAcc))\n",
    "print(\"Betting best odds accuracy: {:.3f}\".format(oddsAcc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

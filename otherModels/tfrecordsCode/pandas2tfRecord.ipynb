{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_ranking as tfr\n",
    "# Get the data\n",
    "runs = pd.read_csv(\"Data/runs.csv\")[:100]\n",
    "races = pd.read_csv(\"Data/races.csv\")\n",
    "## quick fix some nan values\n",
    "\n",
    "runs[\"horse_country\"] = runs[\"horse_country\"].replace(np.nan, runs[\"horse_country\"].mode()[0])\n",
    "runs[\"horse_type\"] = runs[\"horse_type\"].replace(np.nan, runs[\"horse_type\"].mode()[0])\n",
    "\n",
    "EXAMPLE_FEATURES = ['horse_age', 'horse_country', 'horse_type', 'horse_rating']\n",
    "# No context features until the races dataset is incorperated\n",
    "CONTEXT_FEATURES = ['surface', 'distance', 'going']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating test data ...\n",
      "Done creating test data.\n",
      "Creating training data ...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Argument feature_list is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-4ec50c63ec0e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mtest_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Data/test.tfrecord'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0mrowNum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"race_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0mmakeTestAndTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-4ec50c63ec0e>\u001b[0m in \u001b[0;36mmakeTestAndTrain\u001b[0;34m(trainFile, testFile, splitNum)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmakeTestAndTrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestFile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtestTFRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtrainTFRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrowNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrainTFRecord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraceIDNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-4ec50c63ec0e>\u001b[0m in \u001b[0;36mtrainTFRecord\u001b[0;34m(output_file, raceIDNum)\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0;34m'horse_placing'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mhPlacings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         })\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mhorseFeatureList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeatureLists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhorseInfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequenceExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraceContext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_lists\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhorseFeatureList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Argument feature_list is not iterable"
     ]
    }
   ],
   "source": [
    "def makeTestAndTrain(trainFile, testFile, splitNum):\n",
    "    testTFRecord(test_file, rowNum)\n",
    "    trainTFRecord(train_file, rowNum)\n",
    "\n",
    "def trainTFRecord(output_file, raceIDNum):\n",
    "    print(\"Creating training data ...\")\n",
    "    writer = tf.io.TFRecordWriter(output_file)\n",
    "    \"\"\"Build an Example proto\"\"\"\n",
    "    for ID in range(raceIDNum):\n",
    "        race = races.iloc[ID, :]\n",
    "        # Context columns\n",
    "        raceContext = tf.train.Features(feature={\n",
    "            'surface':tf.train.Feature(int64_list=tf.train.Int64List(value=[race[\"surface\"]])),\n",
    "            'distance':tf.train.Feature(int64_list=tf.train.Int64List(value=[race[\"distance\"]])),\n",
    "            'going':tf.train.Feature(bytes_list=tf.train.BytesList(value=[race[\"going\"].encode('utf-8')])),\n",
    "        })\n",
    "        \n",
    "        # Sequence data\n",
    "        raceRuns = runs.loc[runs[\"race_id\"]==ID]\n",
    "        hAge = []\n",
    "        hCountry = []\n",
    "        hType = []\n",
    "        hRating = []\n",
    "        hPlacing = []\n",
    "        for i in range(len(raceRuns)):\n",
    "            run = raceRuns.iloc[i]\n",
    "            \n",
    "            age_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[run['horse_age']]))\n",
    "            hAge.append(age_feature)\n",
    "            \n",
    "            country_feature = tf.train.Feature(bytes_list=tf.train.BytesList(value=[run['horse_country'].encode(\"utf-8\")]))\n",
    "            hCountry.append(country_feature)\n",
    "            \n",
    "            type_feature = tf.train.Feature(bytes_list=tf.train.BytesList(value=[run['horse_type'].encode(\"utf-8\")]))\n",
    "            hType.append(type_feature)\n",
    "            \n",
    "            rating_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[run['horse_rating']]))\n",
    "            hRating.append(rating_feature)\n",
    "            \n",
    "            place_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[run['result']]))\n",
    "            hPlacing.append(place_feature)\n",
    "            \n",
    "        hAges = tf.train.FeatureList(feature=hAge)\n",
    "        hCountries = tf.train.FeatureList(feature=hCountry)\n",
    "        hTypes = tf.train.FeatureList(feature=hType)\n",
    "        hRatings = tf.train.FeatureList(feature=hRating)\n",
    "        hPlacings = tf.train.FeatureList(feature=hPlacing)\n",
    "        \n",
    "        horseInfo = tf.train.FeatureLists(feature_list={\n",
    "            'horse_age':hAges,\n",
    "            'horse_country':hCountries,\n",
    "            'horse_type':hTypes,\n",
    "            'horse_ratings':hRatings,\n",
    "            'horse_placing':hPlacings\n",
    "        })\n",
    "        horseFeatureList = tf.train.FeatureLists(feature_list=horseInfo)\n",
    "\n",
    "        example = tf.train.SequenceExample(context=raceContext, feature_lists=horseFeatureList)\n",
    "        \n",
    "        # Save the examples\n",
    "        writer.write(example.SerializeToString())\n",
    "    \n",
    "    print(\"Done creating training data.\")\n",
    "    writer.close()\n",
    "        \n",
    "        \n",
    "def testTFRecord(output_file, backRaceID):\n",
    "    print(\"Creating test data ...\")\n",
    "    writer = tf.io.TFRecordWriter(output_file)\n",
    "    \"\"\"Build an Example proto\"\"\"\n",
    "    for ID in range(backRaceID, max(races[\"race_id\"])):\n",
    "        race = races.iloc[ID, :]\n",
    "        # Context columns\n",
    "        raceContext = tf.train.Features(feature={\n",
    "            'surface':tf.train.Feature(int64_list=tf.train.Int64List(value=[race[\"surface\"]])),\n",
    "            'distance':tf.train.Feature(int64_list=tf.train.Int64List(value=[race[\"distance\"]])),\n",
    "            'going':tf.train.Feature(bytes_list=tf.train.BytesList(value=[race[\"going\"].encode('utf-8')])),\n",
    "        })\n",
    "        \n",
    "        # Sequence data\n",
    "        raceRuns = runs.loc[runs[\"race_id\"]==ID]\n",
    "        hAge = []\n",
    "        hCountry = []\n",
    "        hType = []\n",
    "        hRating = []\n",
    "        hPlacing = []\n",
    "        for i in range(len(raceRuns)):\n",
    "            run = raceRuns.iloc[i]\n",
    "            \n",
    "            age_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[run['horse_age']]))\n",
    "            hAge.append(age_feature)\n",
    "            \n",
    "            country_feature = tf.train.Feature(bytes_list=tf.train.BytesList(value=[run['horse_country'].encode(\"utf-8\")]))\n",
    "            hCountry.append(country_feature)\n",
    "            \n",
    "            type_feature = tf.train.Feature(bytes_list=tf.train.BytesList(value=[run['horse_type'].encode(\"utf-8\")]))\n",
    "            hType.append(type_feature)\n",
    "            \n",
    "            rating_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[run['horse_rating']]))\n",
    "            hRating.append(rating_feature)\n",
    "            \n",
    "            place_feature = tf.train.Feature(int64_list=tf.train.Int64List(value=[run['result']]))\n",
    "            hPlacing.append(place_feature)\n",
    "            \n",
    "        hAges = tf.train.FeatureList(feature=hAge)\n",
    "        hCountries = tf.train.FeatureList(feature=hCountry)\n",
    "        hTypes = tf.train.FeatureList(feature=hType)\n",
    "        hRatings = tf.train.FeatureList(feature=hRating)\n",
    "        hPlacings = tf.train.FeatureList(feature=hPlacing)\n",
    "        \n",
    "        horseInfo = tf.train.FeatureLists(feature_list={\n",
    "            'horse_age':hAges,\n",
    "            'horse_country':hCountries,\n",
    "            'horse_type':hTypes,\n",
    "            'horse_rating':hRatings,\n",
    "            'horse_placing':hPlacings\n",
    "        })\n",
    "        \n",
    "        example = tf.train.SequenceExample(context=raceContext, feature_lists=horseInfo)\n",
    "        \n",
    "        # Save the examples\n",
    "        writer.write(example.SerializeToString())\n",
    "        \n",
    "    print(\"Done creating test data.\")\n",
    "    writer.close()\n",
    "    \n",
    "        \n",
    "train_file = 'Data/train.tfrecord'\n",
    "test_file = 'Data/test.tfrecord'\n",
    "rowNum = int(max(races[\"race_id\"]) * 0.8)\n",
    "makeTestAndTrain(train_file, test_file, rowNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDat(file):\n",
    "    raw_dataset = tf.data.TFRecordDataset([file])\n",
    "    for raw_record in raw_dataset.take(2):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "        print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printDat(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresDict = {\"horse_age\":tf.io.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "                \"horse_country\":tf.io.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "                \"horse_type\":tf.io.FixedLenSequenceFeature([], dtype=tf.string),\n",
    "                \"horse_age\":tf.io.FixedLenSequenceFeature([], dtype=tf.int64),\n",
    "                \"horse_placing\":tf.io.FixedLenSequenceFeature([], dtype=tf.int64)\n",
    "               }\n",
    "contextDict = {\"distance\":tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "               \"surface\":tf.io.FixedLenFeature([], dtype=tf.int64),\n",
    "               \"going\":tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "              }\n",
    "\n",
    "def parse_tfrecord(example):\n",
    "    context, features = tf.io.parse_single_sequence_example(example, \n",
    "                                                         sequence_features=featuresDict, \n",
    "                                                         context_features=contextDict)\n",
    "    distance = context[\"distance\"]\n",
    "    surface = context[\"surface\"]\n",
    "    going = context[\"going\"]\n",
    "    \n",
    "    age = features[\"horse_age\"]\n",
    "    #country = tf.io.decode_raw(features[\"horse_country\"], tf.uint8)\n",
    "    return distance, surface, going, age, #country\n",
    "    \n",
    "Dataset = tf.data.TFRecordDataset(train_file)\n",
    "Dataset = Dataset.map(parse_tfrecord)\n",
    "#iterator = Dataset.make_one_shot_iterator()\n",
    "\n",
    "batched_dataset = Dataset.batch(1)\n",
    "\n",
    "for next_element in batched_dataset:\n",
    "    tf.print(next_element)\n",
    "#with tf.Session() as sess:\n",
    "#    print(sess.run(iterator.get_next()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-1.0.2.tar.gz (821 kB)\n",
      "\u001b[K     |████████████████████████████████| 821 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from xgboost) (1.18.1)\n",
      "Requirement already satisfied: scipy in /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages (from xgboost) (1.4.1)\n",
      "Building wheels for collected packages: xgboost\n",
      "  Building wheel for xgboost (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for xgboost: filename=xgboost-1.0.2-cp36-cp36m-macosx_10_9_x86_64.whl size=3463804 sha256=13d8a3c6c63fc5146e1a2c21a0dd38b23d4129ec5f650ba64b2f2f074c22955f\n",
      "  Stored in directory: /Users/noahrowe/Library/Caches/pip/wheels/06/0a/03/1dd5317e4ad7882450a41265354839831f7094739ee401043c\n",
      "Successfully built xgboost\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.0.2\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install xgboost\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import six\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow_ranking as tfr\n",
    "    \n",
    "\n",
    "races = pd.read_csv(\"Data/races.csv\")\n",
    "runs = pd.read_csv(\"Data/runs.csv\")\n",
    "\n",
    "runs[\"horse_country\"] = runs[\"horse_country\"].replace(np.nan, runs[\"horse_country\"].mode()[0])\n",
    "runs[\"horse_type\"] = runs[\"horse_type\"].replace(np.nan, runs[\"horse_type\"].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COUNTRY_VOCAB = np.unique(np.array(runs[\"horse_country\"]))\n",
    "TYPE_VOCAB = np.unique(np.array(runs[\"horse_type\"]))\n",
    "GOING_VOCAB = np.unique(np.array(races[\"going\"]))\n",
    "\n",
    "# Store the paths to files containing training and test instances.\n",
    "_TRAIN_DATA_PATH = \"Data/train.tfrecord\"\n",
    "_TEST_DATA_PATH = \"Data/test.tfrecords\"\n",
    "\n",
    "# Store the vocabulary path for query and document tokens.\n",
    "_VOCAB_PATH = \"/tmp/vocab.txt\" # DOES NOT EXIST\n",
    "\n",
    "# The maximum number of documents per query in the dataset.\n",
    "# Document lists are padded or truncated to this size.\n",
    "_LIST_SIZE = 15\n",
    "\n",
    "# The document relevance label.\n",
    "_LABEL_FEATURE = \"horse_placing\"\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "\n",
    "# Learning rate for optimizer.\n",
    "_LEARNING_RATE = 0.05\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 32\n",
    "_HIDDEN_LAYER_DIMS = [\"64\", \"32\", \"16\"]\n",
    "_DROPOUT_RATE = 0.8\n",
    "_GROUP_SIZE = 1  # Pointwise scoring.\n",
    "\n",
    "# Location of model directory and number of training steps.\n",
    "_MODEL_DIR = \"Model/ranking_model_dir\"\n",
    "_NUM_TRAIN_STEPS = 15 * 10\n",
    "tf.executing_eagerly()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context_feature_columns():\n",
    "    '''CONTEXT FEATURES: distance, surface, going'''\n",
    "    \n",
    "    distance_column = tf.feature_column.numeric_column(key=\"distance\")\n",
    "    \n",
    "    surface_column = tf.feature_column.numeric_column(key=\"surface\")\n",
    "    \n",
    "    going_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=\"going\",\n",
    "        vocabulary_list=GOING_VOCAB)\n",
    "    going_one_hot_column = tf.feature_column.indicator_column(going_column)\n",
    "    \n",
    "    return {\"distance\":distance_column,\n",
    "            \"surface\":surface_column,\n",
    "            \"going\":going_one_hot_column}\n",
    "\n",
    "def example_feature_columns():\n",
    "    '''EXAMPLE FEATURES: horse_age, horse_country, horse_type, horse_rating, horse_placing'''\n",
    "    \n",
    "    age_column = tf.feature_column.numeric_column(key=\"horse_age\")\n",
    "    \n",
    "    country_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=\"horse_country\",\n",
    "        vocabulary_list=COUNTRY_VOCAB)\n",
    "    country_one_hot_column = tf.feature_column.indicator_column(country_column)\n",
    "    \n",
    "    type_column = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "        key=\"horse_type\",\n",
    "        vocabulary_list=TYPE_VOCAB)\n",
    "    type_one_hot_column = tf.feature_column.indicator_column(type_column)\n",
    "    \n",
    "    rating_column = tf.feature_column.numeric_column(key=\"horse_rating\")\n",
    "    \n",
    "    placing_column = tf.feature_column.numeric_column(key=\"horse_placing\",\n",
    "                                                      dtype=tf.int64,\n",
    "                                                      default_value=_PADDING_LABEL)\n",
    "    return {\"horse_age\":age_column,\n",
    "            \"horse_country\":country_one_hot_column,\n",
    "            \"horse_type\":type_one_hot_column,\n",
    "            #\"horse_placing\":placing_column\n",
    "           }\n",
    "\n",
    "def input_fn(path, num_epochs=None):\n",
    "    print(\"input_fn\")\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values())\n",
    "    label_column = tf.feature_column.numeric_column(\n",
    "        _LABEL_FEATURE, dtype=tf.int64, default_value=_PADDING_LABEL)\n",
    "    \n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values()) + [label_column])\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern=path,\n",
    "        data_format=tfr.data.ELWC,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        list_size=_LIST_SIZE,\n",
    "        context_feature_spec=context_feature_spec,\n",
    "        example_feature_spec=example_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=False,\n",
    "        num_epochs=num_epochs)\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    label = tf.squeeze(features.pop(_LABEL_FEATURE), axis=2)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    print(\"input_fn\")\n",
    "\n",
    "    return features, label\n",
    "\n",
    "def make_transform_fn():\n",
    "    def _transform_fn(features, mode):\n",
    "        print(\"_transform_fn\")\n",
    "        \"\"\"Defines transform_fn.\"\"\"\n",
    "        context_features, example_features = tfr.feature.encode_listwise_features(\n",
    "            features=features,\n",
    "            context_feature_columns=context_feature_columns(),\n",
    "            example_feature_columns=example_feature_columns(),\n",
    "            mode=mode,\n",
    "            scope=\"transform_layer\")\n",
    "        print(\"_transform_fn\")\n",
    "\n",
    "        return context_features, example_features\n",
    "    return _transform_fn\n",
    "\n",
    "def make_score_fn():\n",
    "    \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "    def _score_fn(context_features, group_features, mode, params, config):\n",
    "        print(\"_score_fn\")\n",
    "        \"\"\"Defines the network to score a group of documents.\"\"\"\n",
    "        with tf.compat.v1.name_scope(\"input_layer\"):\n",
    "            context_input = [\n",
    "                tf.compat.v1.layers.flatten(context_features[name])\n",
    "                for name in sorted(context_feature_columns())\n",
    "            ]\n",
    "            group_input = [\n",
    "                tf.compat.v1.layers.flatten(group_features[name])\n",
    "                for name in sorted(example_feature_columns())\n",
    "            ]\n",
    "            input_layer = tf.concat(context_input + group_input, 1)\n",
    "\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        cur_layer = input_layer\n",
    "        cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "            cur_layer,\n",
    "            training=is_training,\n",
    "            momentum=0.99)\n",
    "\n",
    "        for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "            cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
    "            cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "                cur_layer,\n",
    "                training=is_training,\n",
    "                momentum=0.99)\n",
    "            cur_layer = tf.nn.relu(cur_layer)\n",
    "            cur_layer = tf.compat.v1.layers.dropout(\n",
    "                inputs=cur_layer, rate=_DROPOUT_RATE, training=is_training)\n",
    "            \n",
    "        logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n",
    "        print(\"_score_fn\")\n",
    "        return logits\n",
    "\n",
    "    return _score_fn\n",
    "\n",
    "def eval_metric_fns():\n",
    "    print(\"eval_metric_fns\")\n",
    "    metric_fns = {}\n",
    "    metric_fns.update({\n",
    "        \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
    "        tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "        for topn in [1, 3, 5, 10]\n",
    "    })\n",
    "    print(\"eval_metric_fns\")\n",
    "\n",
    "    return metric_fns\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "    learning_rate=_LEARNING_RATE)\n",
    "\n",
    "def _train_op_fn(loss):\n",
    "    print(\"train_op_fn\")\n",
    "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "    minimize_op = optimizer.minimize(\n",
    "        loss=loss, global_step=tf.compat.v1.train.get_global_step())\n",
    "    \n",
    "    train_op = tf.group([update_ops, minimize_op])\n",
    "    print(\"train_op_fn\")\n",
    "    return train_op\n",
    "\n",
    "def train_and_eval_fn():\n",
    "    print(\"train_and_eval_fn\")\n",
    "    \"\"\"Train and eval function used by `tf.estimator.train_and_evaluate`.\"\"\"\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "        save_checkpoints_steps=1000)\n",
    "\n",
    "    ranker = tf.estimator.Estimator(\n",
    "        model_fn=model_fn,\n",
    "        model_dir=_MODEL_DIR,\n",
    "        config=run_config)\n",
    "\n",
    "    train_input_fn = lambda: input_fn(_TRAIN_DATA_PATH)\n",
    "    eval_input_fn = lambda: input_fn(_TEST_DATA_PATH, num_epochs=1)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "        input_fn=train_input_fn, max_steps=_NUM_TRAIN_STEPS)\n",
    "    eval_spec =  tf.estimator.EvalSpec(\n",
    "        name=\"eval\",\n",
    "        input_fn=eval_input_fn,\n",
    "        throttle_secs=15)\n",
    "    print(\"train_and_eval_fn\")\n",
    "    \n",
    "    return (ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval_metric_fns\n",
      "eval_metric_fns\n"
     ]
    }
   ],
   "source": [
    "_LOSS = tfr.losses.RankingLossKey.APPROX_NDCG_LOSS\n",
    "loss_fn = tfr.losses.make_loss_fn(_LOSS)\n",
    "\n",
    "ranking_head = tfr.head.create_ranking_head(\n",
    "    loss_fn=loss_fn,\n",
    "    eval_metric_fns=eval_metric_fns(),\n",
    "    train_op_fn=_train_op_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = tfr.model.make_groupwise_ranking_fn(\n",
    "    group_score_fn=make_score_fn(),\n",
    "    transform_fn=make_transform_fn(),\n",
    "    group_size=_GROUP_SIZE,\n",
    "    ranking_head=ranking_head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0429 16:23:08.757552 4346017216 model_fn.py:630] Estimator's model_fn (<function _make_model_fn.<locals>._model_fn at 0x1307d82f0>) includes params argument, but params are not passed to Estimator.\n",
      "W0429 16:23:08.770222 4346017216 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0429 16:23:08.771216 4346017216 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0429 16:23:08.806087 4346017216 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_ranking/python/data.py:899: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_and_eval_fn\n",
      "train_and_eval_fn\n",
      "Moving on\n",
      "input_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 16:23:10.370575 4346017216 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4267: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
      "W0429 16:23:10.372037 4346017216 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/feature_column/feature_column_v2.py:4322: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_fn\n",
      "_transform_fn\n",
      "_transform_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 16:23:10.660241 4346017216 deprecation.py:323] From <ipython-input-3-9b06c3623e63>:93: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Flatten instead.\n",
      "W0429 16:23:10.662400 4346017216 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0429 16:23:10.684535 4346017216 deprecation.py:323] From <ipython-input-3-9b06c3623e63>:106: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "W0429 16:23:10.715703 4346017216 deprecation.py:323] From <ipython-input-3-9b06c3623e63>:109: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "W0429 16:23:10.759247 4346017216 deprecation.py:323] From <ipython-input-3-9b06c3623e63>:116: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0429 16:23:10.761630 4346017216 nn_ops.py:4372] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0429 16:23:10.809844 4346017216 nn_ops.py:4372] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0429 16:23:10.857666 4346017216 nn_ops.py:4372] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_score_fn\n",
      "_score_fn\n",
      "train_op_fn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0429 16:23:11.226543 4346017216 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_op_fn\n"
     ]
    }
   ],
   "source": [
    "! rm -rf \"Model/ranking_model_dir\"  # Clean up the model directory.\n",
    "ranker, train_spec, eval_spec = train_and_eval_fn()\n",
    "print(\"Moving on\")\n",
    "tf.estimator.train_and_evaluate(ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(os.path.abspath(inspect.getfile(tf.estimator.train_and_evaluate)))\n",
    "print(os.path.abspath(inspect.getfile(tf.estimator.Estimator)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fa26995b07e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Ranker.train is the crashing issue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Ranker.train is the crashing issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

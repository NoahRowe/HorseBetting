{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-04-30 20:54:47--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/vocab.txt\n",
      "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
      "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 231508 (226K) [text/plain]\n",
      "Saving to: ‘/tmp/vocab.txt’\n",
      "\n",
      "/tmp/vocab.txt      100%[===================>] 226.08K   989KB/s    in 0.2s    \n",
      "\n",
      "2020-04-30 20:54:48 (989 KB/s) - ‘/tmp/vocab.txt’ saved [231508/231508]\n",
      "\n",
      "--2020-04-30 20:54:48--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/ELWC/train.tfrecords\n",
      "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
      "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 156410796 (149M)\n",
      "Saving to: ‘/tmp/train.tfrecords’\n",
      "\n",
      "/tmp/train.tfrecord 100%[===================>] 149.16M  20.8MB/s    in 7.0s    \n",
      "\n",
      "2020-04-30 20:54:55 (21.3 MB/s) - ‘/tmp/train.tfrecords’ saved [156410796/156410796]\n",
      "\n",
      "--2020-04-30 20:54:55--  http://ciir.cs.umass.edu/downloads/Antique/tf-ranking//ELWC/test.tfrecords\n",
      "Resolving ciir.cs.umass.edu (ciir.cs.umass.edu)... 128.119.246.154\n",
      "Connecting to ciir.cs.umass.edu (ciir.cs.umass.edu)|128.119.246.154|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 12432621 (12M)\n",
      "Saving to: ‘/tmp/test.tfrecords’\n",
      "\n",
      "/tmp/test.tfrecords 100%[===================>]  11.86M  11.7MB/s    in 1.0s    \n",
      "\n",
      "2020-04-30 20:54:57 (11.7 MB/s) - ‘/tmp/test.tfrecords’ saved [12432621/12432621]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget -O \"/tmp/vocab.txt\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/vocab.txt\"\n",
    "!wget -O \"/tmp/train.tfrecords\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking/ELWC/train.tfrecords\"\n",
    "!wget -O \"/tmp/test.tfrecords\" \"http://ciir.cs.umass.edu/downloads/Antique/tf-ranking//ELWC/test.tfrecords\"\n",
    "\n",
    "#https://colab.research.google.com/github/tensorflow/ranking/blob/master/tensorflow_ranking/examples/handling_sparse_features.ipynb#scrollTo=45WYaJNaGfLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing TensorFlow 2.1.0. This will take a minute, ignore the warnings.\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Found existing installation: grpcio 1.28.1\n",
      "Uninstalling grpcio-1.28.1:\n",
      "  Successfully uninstalled grpcio-1.28.1\n",
      "\u001b[33mWARNING: You are using pip version 20.0.2; however, version 20.1 is available.\n",
      "You should consider upgrading via the '/Library/Frameworks/Python.framework/Versions/3.6/bin/python3.6 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print('Installing TensorFlow 2.1.0. This will take a minute, ignore the warnings.')\n",
    "!pip install -q tensorflow==2.1.0\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "\n",
    "# This is needed for tensorboard compatibility.\n",
    "!pip uninstall -y grpcio\n",
    "!pip install -q grpcio>=1.24.3\n",
    "import six\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import tensorflow_ranking as tfr\n",
    "except ImportError:\n",
    "    !pip install -q tensorflow_ranking\n",
    "    import tensorflow_ranking as tfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the paths to files containing training and test instances.\n",
    "_TRAIN_DATA_PATH = \"/tmp/train.tfrecords\"\n",
    "_TEST_DATA_PATH = \"/tmp/test.tfrecords\"\n",
    "\n",
    "# Store the vocabulary path for query and document tokens.\n",
    "_VOCAB_PATH = \"/tmp/vocab.txt\"\n",
    "\n",
    "# The maximum number of documents per query in the dataset.\n",
    "# Document lists are padded or truncated to this size.\n",
    "_LIST_SIZE = 50\n",
    "\n",
    "# The document relevance label.\n",
    "_LABEL_FEATURE = \"relevance\"\n",
    "\n",
    "# Padding labels are set negative so that the corresponding examples can be\n",
    "# ignored in loss and metrics.\n",
    "_PADDING_LABEL = -1\n",
    "\n",
    "# Learning rate for optimizer.\n",
    "_LEARNING_RATE = 0.05\n",
    "\n",
    "# Parameters to the scoring function.\n",
    "_BATCH_SIZE = 32\n",
    "_HIDDEN_LAYER_DIMS = [\"64\", \"32\", \"16\"]\n",
    "_DROPOUT_RATE = 0.8\n",
    "_GROUP_SIZE = 1  # Pointwise scoring.\n",
    "\n",
    "# Location of model directory and number of training steps.\n",
    "_MODEL_DIR = \"Model/ranking_model_dir\"\n",
    "_NUM_TRAIN_STEPS = 15 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_EMBEDDING_DIMENSION = 20\n",
    "\n",
    "def context_feature_columns():\n",
    "    \"\"\"Returns context feature names to column definitions.\"\"\"\n",
    "    sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "      key=\"query_tokens\",\n",
    "      vocabulary_file=_VOCAB_PATH)\n",
    "    query_embedding_column = tf.feature_column.embedding_column(\n",
    "      sparse_column, _EMBEDDING_DIMENSION)\n",
    "    return {\"query_tokens\": query_embedding_column}\n",
    "\n",
    "def example_feature_columns():\n",
    "    \"\"\"Returns the example feature columns.\"\"\"\n",
    "    sparse_column = tf.feature_column.categorical_column_with_vocabulary_file(\n",
    "      key=\"document_tokens\",\n",
    "      vocabulary_file=_VOCAB_PATH)\n",
    "    document_embedding_column = tf.feature_column.embedding_column(\n",
    "      sparse_column, _EMBEDDING_DIMENSION)\n",
    "    return {\"document_tokens\": document_embedding_column}\n",
    "\n",
    "def input_fn(path, num_epochs=None):\n",
    "    context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values())\n",
    "    label_column = tf.feature_column.numeric_column(\n",
    "        _LABEL_FEATURE, dtype=tf.int64, default_value=_PADDING_LABEL)\n",
    "    example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values()) + [label_column])\n",
    "    dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern=path,\n",
    "        data_format=tfr.data.ELWC,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        list_size=_LIST_SIZE,\n",
    "        context_feature_spec=context_feature_spec,\n",
    "        example_feature_spec=example_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=False,\n",
    "        num_epochs=num_epochs)\n",
    "\n",
    "    features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "    label = tf.squeeze(features.pop(_LABEL_FEATURE), axis=2)\n",
    "    label = tf.cast(label, tf.float32)\n",
    "    print(label)\n",
    "    print(num_epochs)\n",
    "    print(path)\n",
    "    \n",
    "    return features, label\n",
    "\n",
    "def make_transform_fn():\n",
    "    def _transform_fn(features, mode):\n",
    "        \"\"\"Defines transform_fn.\"\"\"\n",
    "        context_features, example_features = tfr.feature.encode_listwise_features(\n",
    "            features=features,\n",
    "            context_feature_columns=context_feature_columns(),\n",
    "            example_feature_columns=example_feature_columns(),\n",
    "            mode=mode,\n",
    "            scope=\"transform_layer\")\n",
    "\n",
    "        return context_features, example_features\n",
    "    return _transform_fn\n",
    "\n",
    "def make_score_fn():\n",
    "    \"\"\"Returns a scoring function to build `EstimatorSpec`.\"\"\"\n",
    "\n",
    "    def _score_fn(context_features, group_features, mode, params, config):\n",
    "        \"\"\"Defines the network to score a group of documents.\"\"\"\n",
    "        with tf.compat.v1.name_scope(\"input_layer\"):\n",
    "            context_input = [\n",
    "              tf.compat.v1.layers.flatten(context_features[name])\n",
    "              for name in sorted(context_feature_columns())\n",
    "          ]\n",
    "            group_input = [\n",
    "                tf.compat.v1.layers.flatten(group_features[name])\n",
    "                  for name in sorted(example_feature_columns())\n",
    "          ]\n",
    "            input_layer = tf.concat(context_input + group_input, 1)\n",
    "\n",
    "            is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "            cur_layer = input_layer\n",
    "            cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "                cur_layer,\n",
    "                training=is_training,\n",
    "                momentum=0.99)\n",
    "\n",
    "        for i, layer_width in enumerate(int(d) for d in _HIDDEN_LAYER_DIMS):\n",
    "            cur_layer = tf.compat.v1.layers.dense(cur_layer, units=layer_width)\n",
    "            cur_layer = tf.compat.v1.layers.batch_normalization(\n",
    "                cur_layer,\n",
    "                training=is_training,\n",
    "                momentum=0.99)\n",
    "            cur_layer = tf.nn.relu(cur_layer)\n",
    "            cur_layer = tf.compat.v1.layers.dropout(\n",
    "                inputs=cur_layer, rate=_DROPOUT_RATE, training=is_training)\n",
    "        logits = tf.compat.v1.layers.dense(cur_layer, units=_GROUP_SIZE)\n",
    "        return logits\n",
    "\n",
    "    return _score_fn\n",
    "\n",
    "def eval_metric_fns():\n",
    "    \"\"\"Returns a dict from name to metric functions.\n",
    "\n",
    "    This can be customized as follows. Care must be taken when handling padded\n",
    "    lists.\n",
    "\n",
    "    def _auc(labels, predictions, features):\n",
    "    is_label_valid = tf_reshape(tf.greater_equal(labels, 0.), [-1, 1])\n",
    "    clean_labels = tf.boolean_mask(tf.reshape(labels, [-1, 1], is_label_valid)\n",
    "    clean_pred = tf.boolean_maks(tf.reshape(predictions, [-1, 1], is_label_valid)\n",
    "    return tf.metrics.auc(clean_labels, tf.sigmoid(clean_pred), ...)\n",
    "    metric_fns[\"auc\"] = _auc\n",
    "\n",
    "    Returns:\n",
    "    A dict mapping from metric name to a metric function with above signature.\n",
    "    \"\"\"\n",
    "    metric_fns = {}\n",
    "    metric_fns.update({\n",
    "      \"metric/ndcg@%d\" % topn: tfr.metrics.make_ranking_metric_fn(\n",
    "          tfr.metrics.RankingMetricKey.NDCG, topn=topn)\n",
    "      for topn in [1, 3, 5, 10]\n",
    "    })\n",
    "\n",
    "    return metric_fns\n",
    "\n",
    "def _train_op_fn(loss):\n",
    "    \"\"\"Defines train op used in ranking head.\"\"\"\n",
    "    update_ops = tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.UPDATE_OPS)\n",
    "    minimize_op = optimizer.minimize(\n",
    "      loss=loss, global_step=tf.compat.v1.train.get_global_step())\n",
    "    train_op = tf.group([update_ops, minimize_op])\n",
    "    return train_op\n",
    "\n",
    "def train_and_eval_fn():\n",
    "    \"\"\"Train and eval function used by `tf.estimator.train_and_evaluate`.\"\"\"\n",
    "    run_config = tf.estimator.RunConfig(\n",
    "      save_checkpoints_steps=1000)\n",
    "    ranker = tf.estimator.Estimator(\n",
    "      model_fn=model_fn,\n",
    "      model_dir=_MODEL_DIR,\n",
    "      config=run_config)\n",
    "\n",
    "    train_input_fn = lambda: input_fn(_TRAIN_DATA_PATH)\n",
    "    eval_input_fn = lambda: input_fn(_TEST_DATA_PATH, num_epochs=1)\n",
    "\n",
    "    train_spec = tf.estimator.TrainSpec(\n",
    "      input_fn=train_input_fn, max_steps=_NUM_TRAIN_STEPS)\n",
    "    eval_spec =  tf.estimator.EvalSpec(\n",
    "          name=\"eval\",\n",
    "          input_fn=eval_input_fn,\n",
    "          throttle_secs=15)\n",
    "    return (ranker, train_spec, eval_spec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0430 20:55:07.158591 4514137536 model_fn.py:630] Estimator's model_fn (<function _make_model_fn.<locals>._model_fn at 0x133978620>) includes params argument, but params are not passed to Estimator.\n",
      "W0430 20:55:07.212261 4514137536 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "W0430 20:55:07.221784 4514137536 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "W0430 20:55:07.500047 4514137536 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_ranking/python/data.py:899: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(32, 50), dtype=float32, device=/device:CPU:0)\n",
      "None\n",
      "/tmp/train.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0430 20:55:09.599272 4514137536 deprecation.py:323] From <ipython-input-4-7d539fe49ece>:69: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Flatten instead.\n",
      "W0430 20:55:09.601973 4514137536 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:332: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "W0430 20:55:09.694931 4514137536 deprecation.py:323] From <ipython-input-4-7d539fe49ece>:82: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n",
      "W0430 20:55:09.724939 4514137536 deprecation.py:323] From <ipython-input-4-7d539fe49ece>:85: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "W0430 20:55:09.778728 4514137536 deprecation.py:323] From <ipython-input-4-7d539fe49ece>:92: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "W0430 20:55:09.781368 4514137536 nn_ops.py:4372] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0430 20:55:09.849337 4514137536 nn_ops.py:4372] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0430 20:55:09.906141 4514137536 nn_ops.py:4372] Large dropout rate: 0.8 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n",
      "W0430 20:55:10.310615 4514137536 deprecation.py:506] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/training/adagrad.py:76: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0430 20:56:22.934764 4514137536 deprecation.py:323] From /Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to delete files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n",
      "Tensor(\"Cast:0\", shape=(None, 50), dtype=float32, device=/device:CPU:0)\n",
      "1\n",
      "/tmp/test.tfrecords\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'labels_mean': 1.9630322,\n",
       "  'logits_mean': 2.0652447,\n",
       "  'loss': -0.8387331,\n",
       "  'metric/ndcg@1': 0.7264286,\n",
       "  'metric/ndcg@10': 0.85479635,\n",
       "  'metric/ndcg@3': 0.77445656,\n",
       "  'metric/ndcg@5': 0.80803823,\n",
       "  'global_step': 15000},\n",
       " [])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_LOSS = tfr.losses.RankingLossKey.APPROX_NDCG_LOSS\n",
    "loss_fn = tfr.losses.make_loss_fn(_LOSS)\n",
    "\n",
    "optimizer = tf.compat.v1.train.AdagradOptimizer(\n",
    "    learning_rate=_LEARNING_RATE)\n",
    "\n",
    "ranking_head = tfr.head.create_ranking_head(\n",
    "      loss_fn=loss_fn,\n",
    "      eval_metric_fns=eval_metric_fns(),\n",
    "      train_op_fn=_train_op_fn)\n",
    "\n",
    "model_fn = tfr.model.make_groupwise_ranking_fn(\n",
    "          group_score_fn=make_score_fn(),\n",
    "          transform_fn=make_transform_fn(),\n",
    "          group_size=_GROUP_SIZE,\n",
    "          ranking_head=ranking_head)\n",
    "\n",
    "! rm -rf \"Model/ranking_model_dir\"  # Clean up the model directory.\n",
    "ranker, train_spec, eval_spec = train_and_eval_fn()\n",
    "tf.estimator.train_and_evaluate(ranker, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        context_feature_columns().values())\n",
    "label_column = tf.feature_column.numeric_column(\n",
    "        _LABEL_FEATURE, dtype=tf.int64, default_value=_PADDING_LABEL)\n",
    "example_feature_spec = tf.feature_column.make_parse_example_spec(\n",
    "        list(example_feature_columns().values()) + [label_column])\n",
    "dataset = tfr.data.build_ranking_dataset(\n",
    "        file_pattern=_TRAIN_DATA_PATH,\n",
    "        data_format=tfr.data.ELWC,\n",
    "        batch_size=_BATCH_SIZE,\n",
    "        list_size=_LIST_SIZE,\n",
    "        context_feature_spec=context_feature_spec,\n",
    "        example_feature_spec=example_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=False,\n",
    "        num_epochs=None)\n",
    "\n",
    "features = tf.compat.v1.data.make_one_shot_iterator(dataset).get_next()\n",
    "label = tf.squeeze(features.pop(_LABEL_FEATURE), axis=2)\n",
    "label = tf.cast(label, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 50), dtype=float32, numpy=\n",
       "array([[ 1.,  2.,  3., ..., -1., -1., -1.],\n",
       "       [ 3.,  3.,  2., ..., -1., -1., -1.],\n",
       "       [ 1.,  3.,  2., ..., -1., -1., -1.],\n",
       "       ...,\n",
       "       [ 2.,  1.,  3., ..., -1., -1., -1.],\n",
       "       [ 2.,  3.,  1., ..., -1., -1., -1.],\n",
       "       [ 2.,  3.,  3., ..., -1., -1., -1.]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(indices=tf.Tensor(\n",
      "[[ 0  0]\n",
      " [ 0  1]\n",
      " [ 0  2]\n",
      " [ 0  3]\n",
      " [ 0  4]\n",
      " [ 0  5]\n",
      " [ 0  6]\n",
      " [ 0  7]\n",
      " [ 0  8]\n",
      " [ 0  9]\n",
      " [ 0 10]\n",
      " [ 0 11]\n",
      " [ 0 12]\n",
      " [ 1  0]\n",
      " [ 1  1]\n",
      " [ 1  2]\n",
      " [ 1  3]\n",
      " [ 1  4]\n",
      " [ 1  5]\n",
      " [ 1  6]\n",
      " [ 1  7]\n",
      " [ 1  8]\n",
      " [ 1  9]\n",
      " [ 1 10]\n",
      " [ 1 11]\n",
      " [ 1 12]\n",
      " [ 1 13]\n",
      " [ 2  0]\n",
      " [ 2  1]\n",
      " [ 2  2]\n",
      " [ 2  3]\n",
      " [ 2  4]\n",
      " [ 2  5]\n",
      " [ 2  6]\n",
      " [ 2  7]\n",
      " [ 3  0]\n",
      " [ 3  1]\n",
      " [ 3  2]\n",
      " [ 3  3]\n",
      " [ 3  4]\n",
      " [ 3  5]\n",
      " [ 3  6]\n",
      " [ 3  7]\n",
      " [ 4  0]\n",
      " [ 4  1]\n",
      " [ 4  2]\n",
      " [ 4  3]\n",
      " [ 4  4]\n",
      " [ 4  5]\n",
      " [ 4  6]\n",
      " [ 4  7]\n",
      " [ 4  8]\n",
      " [ 4  9]\n",
      " [ 5  0]\n",
      " [ 5  1]\n",
      " [ 5  2]\n",
      " [ 5  3]\n",
      " [ 5  4]\n",
      " [ 5  5]\n",
      " [ 5  6]\n",
      " [ 5  7]\n",
      " [ 5  8]\n",
      " [ 6  0]\n",
      " [ 6  1]\n",
      " [ 6  2]\n",
      " [ 6  3]\n",
      " [ 6  4]\n",
      " [ 6  5]\n",
      " [ 6  6]\n",
      " [ 6  7]\n",
      " [ 6  8]\n",
      " [ 7  0]\n",
      " [ 7  1]\n",
      " [ 7  2]\n",
      " [ 7  3]\n",
      " [ 7  4]\n",
      " [ 7  5]\n",
      " [ 7  6]\n",
      " [ 7  7]\n",
      " [ 7  8]\n",
      " [ 7  9]\n",
      " [ 7 10]\n",
      " [ 7 11]\n",
      " [ 7 12]\n",
      " [ 7 13]\n",
      " [ 8  0]\n",
      " [ 8  1]\n",
      " [ 8  2]\n",
      " [ 8  3]\n",
      " [ 8  4]\n",
      " [ 8  5]\n",
      " [ 8  6]\n",
      " [ 8  7]\n",
      " [ 8  8]\n",
      " [ 8  9]\n",
      " [ 8 10]\n",
      " [ 8 11]\n",
      " [ 8 12]\n",
      " [ 8 13]\n",
      " [ 8 14]\n",
      " [ 8 15]\n",
      " [ 8 16]\n",
      " [ 8 17]\n",
      " [ 8 18]\n",
      " [ 8 19]\n",
      " [ 8 20]\n",
      " [ 8 21]\n",
      " [ 8 22]\n",
      " [ 8 23]\n",
      " [ 8 24]\n",
      " [ 8 25]\n",
      " [ 8 26]\n",
      " [ 8 27]\n",
      " [ 8 28]\n",
      " [ 8 29]\n",
      " [ 8 30]\n",
      " [ 8 31]\n",
      " [ 8 32]\n",
      " [ 8 33]\n",
      " [ 8 34]\n",
      " [ 8 35]\n",
      " [ 9  0]\n",
      " [ 9  1]\n",
      " [ 9  2]\n",
      " [ 9  3]\n",
      " [ 9  4]\n",
      " [ 9  5]\n",
      " [ 9  6]\n",
      " [ 9  7]\n",
      " [ 9  8]\n",
      " [ 9  9]\n",
      " [ 9 10]\n",
      " [ 9 11]\n",
      " [ 9 12]\n",
      " [ 9 13]\n",
      " [ 9 14]\n",
      " [ 9 15]\n",
      " [10  0]\n",
      " [10  1]\n",
      " [10  2]\n",
      " [10  3]\n",
      " [10  4]\n",
      " [10  5]\n",
      " [10  6]\n",
      " [11  0]\n",
      " [11  1]\n",
      " [11  2]\n",
      " [11  3]\n",
      " [11  4]\n",
      " [11  5]\n",
      " [11  6]\n",
      " [12  0]\n",
      " [12  1]\n",
      " [12  2]\n",
      " [12  3]\n",
      " [12  4]\n",
      " [12  5]\n",
      " [12  6]\n",
      " [12  7]\n",
      " [12  8]\n",
      " [12  9]\n",
      " [12 10]\n",
      " [12 11]\n",
      " [13  0]\n",
      " [13  1]\n",
      " [13  2]\n",
      " [13  3]\n",
      " [13  4]\n",
      " [13  5]\n",
      " [13  6]\n",
      " [13  7]\n",
      " [14  0]\n",
      " [14  1]\n",
      " [14  2]\n",
      " [14  3]\n",
      " [14  4]\n",
      " [14  5]\n",
      " [14  6]\n",
      " [14  7]\n",
      " [14  8]\n",
      " [14  9]\n",
      " [14 10]\n",
      " [14 11]\n",
      " [14 12]\n",
      " [14 13]\n",
      " [14 14]\n",
      " [14 15]\n",
      " [14 16]\n",
      " [14 17]\n",
      " [14 18]\n",
      " [14 19]\n",
      " [14 20]\n",
      " [14 21]\n",
      " [14 22]\n",
      " [14 23]\n",
      " [14 24]\n",
      " [14 25]\n",
      " [14 26]\n",
      " [15  0]\n",
      " [15  1]\n",
      " [15  2]\n",
      " [15  3]\n",
      " [15  4]\n",
      " [15  5]\n",
      " [15  6]\n",
      " [15  7]\n",
      " [15  8]\n",
      " [15  9]\n",
      " [15 10]\n",
      " [15 11]\n",
      " [15 12]\n",
      " [15 13]\n",
      " [15 14]\n",
      " [15 15]\n",
      " [15 16]\n",
      " [15 17]\n",
      " [15 18]\n",
      " [15 19]\n",
      " [15 20]\n",
      " [15 21]\n",
      " [15 22]\n",
      " [15 23]\n",
      " [15 24]\n",
      " [15 25]\n",
      " [16  0]\n",
      " [16  1]\n",
      " [16  2]\n",
      " [16  3]\n",
      " [16  4]\n",
      " [16  5]\n",
      " [16  6]\n",
      " [16  7]\n",
      " [16  8]\n",
      " [16  9]\n",
      " [16 10]\n",
      " [16 11]\n",
      " [16 12]\n",
      " [16 13]\n",
      " [16 14]\n",
      " [16 15]\n",
      " [16 16]\n",
      " [16 17]\n",
      " [17  0]\n",
      " [17  1]\n",
      " [17  2]\n",
      " [17  3]\n",
      " [17  4]\n",
      " [17  5]\n",
      " [17  6]\n",
      " [17  7]\n",
      " [17  8]\n",
      " [17  9]\n",
      " [17 10]\n",
      " [17 11]\n",
      " [17 12]\n",
      " [17 13]\n",
      " [17 14]\n",
      " [17 15]\n",
      " [18  0]\n",
      " [18  1]\n",
      " [18  2]\n",
      " [18  3]\n",
      " [18  4]\n",
      " [18  5]\n",
      " [18  6]\n",
      " [19  0]\n",
      " [19  1]\n",
      " [19  2]\n",
      " [19  3]\n",
      " [19  4]\n",
      " [19  5]\n",
      " [19  6]\n",
      " [19  7]\n",
      " [19  8]\n",
      " [19  9]\n",
      " [19 10]\n",
      " [19 11]\n",
      " [19 12]\n",
      " [19 13]\n",
      " [19 14]\n",
      " [19 15]\n",
      " [19 16]\n",
      " [19 17]\n",
      " [20  0]\n",
      " [20  1]\n",
      " [20  2]\n",
      " [20  3]\n",
      " [20  4]\n",
      " [20  5]\n",
      " [20  6]\n",
      " [20  7]\n",
      " [20  8]\n",
      " [20  9]\n",
      " [20 10]\n",
      " [20 11]\n",
      " [20 12]\n",
      " [21  0]\n",
      " [21  1]\n",
      " [21  2]\n",
      " [21  3]\n",
      " [21  4]\n",
      " [21  5]\n",
      " [21  6]\n",
      " [21  7]\n",
      " [21  8]\n",
      " [21  9]\n",
      " [22  0]\n",
      " [22  1]\n",
      " [22  2]\n",
      " [22  3]\n",
      " [22  4]\n",
      " [22  5]\n",
      " [22  6]\n",
      " [22  7]\n",
      " [22  8]\n",
      " [23  0]\n",
      " [23  1]\n",
      " [23  2]\n",
      " [23  3]\n",
      " [23  4]\n",
      " [23  5]\n",
      " [23  6]\n",
      " [23  7]\n",
      " [23  8]\n",
      " [23  9]\n",
      " [23 10]\n",
      " [24  0]\n",
      " [24  1]\n",
      " [24  2]\n",
      " [24  3]\n",
      " [24  4]\n",
      " [24  5]\n",
      " [24  6]\n",
      " [24  7]\n",
      " [24  8]\n",
      " [24  9]\n",
      " [24 10]\n",
      " [25  0]\n",
      " [25  1]\n",
      " [25  2]\n",
      " [25  3]\n",
      " [25  4]\n",
      " [25  5]\n",
      " [25  6]\n",
      " [26  0]\n",
      " [26  1]\n",
      " [26  2]\n",
      " [26  3]\n",
      " [26  4]\n",
      " [26  5]\n",
      " [26  6]\n",
      " [27  0]\n",
      " [27  1]\n",
      " [27  2]\n",
      " [27  3]\n",
      " [27  4]\n",
      " [27  5]\n",
      " [27  6]\n",
      " [28  0]\n",
      " [28  1]\n",
      " [28  2]\n",
      " [28  3]\n",
      " [28  4]\n",
      " [28  5]\n",
      " [28  6]\n",
      " [28  7]\n",
      " [29  0]\n",
      " [29  1]\n",
      " [29  2]\n",
      " [29  3]\n",
      " [29  4]\n",
      " [29  5]\n",
      " [29  6]\n",
      " [30  0]\n",
      " [30  1]\n",
      " [30  2]\n",
      " [30  3]\n",
      " [30  4]\n",
      " [30  5]\n",
      " [30  6]\n",
      " [30  7]\n",
      " [30  8]\n",
      " [30  9]\n",
      " [30 10]\n",
      " [30 11]\n",
      " [30 12]\n",
      " [30 13]\n",
      " [30 14]\n",
      " [31  0]\n",
      " [31  1]\n",
      " [31  2]\n",
      " [31  3]\n",
      " [31  4]\n",
      " [31  5]\n",
      " [31  6]], shape=(395, 2), dtype=int64), values=tf.Tensor(\n",
      "[b'why' b'do' b'human' b'bee' b'##ing' b'h' b'##v' b'to' b'bel' b'##ive'\n",
      " b'in' b'god' b'?' b'what' b'is' b'the' b'best' b'way' b'someone'\n",
      " b'taught' b'you' b'how' b'to' b'do' b'something' b'new' b'?' b'how' b'to'\n",
      " b'increase' b'mas' b'##cu' b'##lini' b'##ty' b'?' b'how' b'do' b'you'\n",
      " b'trim' b'fresh' b'green' b'beans' b'?' b'does' b'anybody' b'know' b'how'\n",
      " b'to' b'make' b'homemade' b'ste' b'##roids' b'?' b'what' b'happens' b'to'\n",
      " b'bees' b'in' b'the' b'winter' b'time' b'?' b'how' b'does' b'one' b'give'\n",
      " b'up' b'all' b'parental' b'rights' b'?' b'why' b'do' b'some' b'black'\n",
      " b'women' b'jerk' b'their' b'heads' b'side' b'to' b'side' b'while'\n",
      " b'talking' b'?' b'is' b'there' b'a' b'starting' b'(' b'origin' b')' b'of'\n",
      " b'the' b'earth' b'.' b'.' b'.' b'.' b'if' b'there' b',' b',' b',' b'then'\n",
      " b'why' b'it' b'is' b'started' b'.' b'.' b'.' b'how' b'it' b'is'\n",
      " b'started' b'.' b'.' b'tell' b'me' b'?' b'i' b'just' b'got' b'a'\n",
      " b'kitten' b'she' b'is' b'about' b'7' b'weeks' b'what' b'can' b'i' b'feed'\n",
      " b'her' b'?' b'how' b'can' b'we' b'era' b'##dicate' b'racism' b'?' b'what'\n",
      " b'is' b'the' b'meaning' b'to' b'life' b'?' b'what' b'is' b'the' b'cute'\n",
      " b'##st' b'breed' b'of' b'the' b'dog' b'and' b'why' b'?' b'what' b'is'\n",
      " b'a' b\"'\" b'fort' b'##night' b\"'\" b'?' b'what' b'if' b'auto' b'app'\n",
      " b'##rai' b'##ser' b'app' b'##rai' b'##ses' b'car' b'at' b'lower' b'##val'\n",
      " b'##ue' b'2' b'repair' b'damage' b'?' b'what' b'if' b'the' b'auto'\n",
      " b'shop' b'of' b'choice' b'cost' b'higher' b'how' b'to' b'make' b'ch'\n",
      " b'##lor' b'##ates' b'from' b'sul' b'##puri' b'##c' b'acid' b',' b'ca'\n",
      " b'##ust' b'##ic' b'soda' b'&' b'so' b'##d' b'.' b'h' b'##yp' b'##och'\n",
      " b'##lor' b'##ite' b'?' b'what' b'were' b'the' b'differences' b'between'\n",
      " b'hoover' b\"'\" b's' b'and' b'f' b'##dr' b\"'\" b's' b'of' b'handling'\n",
      " b'the' b'depression' b'?' b'why' b'is' b'speaking' b'in' b'tongues'\n",
      " b'evidence' b'of' b'the' b'in' b'##fi' b'##lling' b'of' b'the' b'holy'\n",
      " b'ghost' b'?' b'what' b'is' b'the' b'philosophy' b'of' b'education' b'?'\n",
      " b'why' b'did' b'eli' b'##e' b'wi' b'##ese' b'##l' b'choose' b'\"' b'night'\n",
      " b'\"' b'as' b'his' b'title' b'for' b'his' b'memoir' b'?' b'what' b'is'\n",
      " b'the' b'easiest' b'way' b'to' b'clear' b'fl' b'##em' b'from' b'your'\n",
      " b'throat' b'?' b'what' b'is' b'the' b'difference' b'between' b'equity'\n",
      " b'and' b'common' b'##law' b'?' b'how' b'was' b'australia' b'involved'\n",
      " b'in' b'world' b'war' b'1' b'?' b'how' b'do' b'new' b'ideas' b'come'\n",
      " b'across' b'people' b\"'\" b's' b'mind' b'?' b'what' b'were' b'the'\n",
      " b'causes' b'of' b'the' b'current' b'war' b'in' b'iraq' b'?' b'why' b'my'\n",
      " b'dog' b'keep' b'throwing' b'up' b'?' b'why' b'is' b'olive' b'card'\n",
      " b'##enas' b'ugly' b'?' b'why' b'is' b'god' b'\"' b'male' b'\"' b'?' b'why'\n",
      " b'does' b'my' b'cat' b'attack' b'my' b'feet' b'?' b'how' b'can' b'i'\n",
      " b'burn' b'some' b'fat' b'?' b'how' b'good' b'is' b'the' b'clinical'\n",
      " b'pharmacy' b'practice' b'in' b'australia' b'in' b'comparison' b'to'\n",
      " b'the' b'usa' b'?' b'how' b'can' b'you' b'reduce' b'hang' b'##overs' b'?'], shape=(395,), dtype=string), dense_shape=tf.Tensor([32 36], shape=(2,), dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(features[\"query_tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'document_tokens': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x13623b8d0>,\n",
       " 'query_tokens': <tensorflow.python.framework.sparse_tensor.SparseTensor at 0x1364a0048>}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
